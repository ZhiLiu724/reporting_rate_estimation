{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_data/sample_reports_df.csv', parse_dates=['SRCreatedDate', 'InsCreatedDate', 'WOCreatedDate']).head(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_observation_start_end_time(df, \n",
    "                                        incident_identifier_col, \n",
    "                                        observation_start_col,\n",
    "                                        observation_start_agg_method,\n",
    "                                        observation_end_col, \n",
    "                                        observation_end_agg_method, \n",
    "                                        max_duration):\n",
    "    \"\"\"\n",
    "    Calculate the observation end time for each incident.\n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        the raw reports dataframe\n",
    "    incident_identifier_col : str\n",
    "        the column name for the incident identifier\n",
    "    observation_end_col : str, or list of str\n",
    "        the column name for the observation end time\n",
    "    max_duration : str\n",
    "        the maximum duration of the observation interval, in days\n",
    "    \"\"\"\n",
    "    cols_to_agg = observation_start_col + observation_end_col\n",
    "    agg_methods = observation_start_agg_method + observation_end_agg_method\n",
    "    agg_dict = dict(zip(cols_to_agg, agg_methods))\n",
    "\n",
    "    grouped = df.groupby(incident_identifier_col).agg(agg_dict).reset_index()\n",
    "\n",
    "    # the observation start time is the minimum of the observation start time columns\n",
    "    grouped['observation_start_time'] = grouped[observation_start_col].min(axis=1)\n",
    "\n",
    "    # add a columns for max duration, then calculate the observation end time\n",
    "    grouped['max_duration'] = grouped['observation_start_time'] + pd.Timedelta(max_duration, unit='d')\n",
    "    observation_end_col.append('max_duration')\n",
    "    grouped['observation_end_time'] = grouped[observation_end_col].min(axis=1)\n",
    "\n",
    "    # drop the columns that are no longer needed\n",
    "    cols_to_keep = [incident_identifier_col, 'observation_start_time', 'observation_end_time']\n",
    "    grouped = grouped[cols_to_keep]\n",
    "\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_incidents_df(reports_df,\n",
    "                        incident_identifier_col,\n",
    "                        observation_start_col,\n",
    "                        observation_end_col, \n",
    "                        reports_identifier_col = None,\n",
    "                        observation_start_agg_method = None,\n",
    "                        observation_end_agg_method = None,\n",
    "                        max_duration = 100,\n",
    "                        covariates_cont = None,\n",
    "                        covariates_cont_agg_method = None,\n",
    "                        covariates_cat = None,\n",
    "                        covariates_cat_agg_method = None,\n",
    "                        dropna = True,\n",
    "                        filter_short_duration = True,\n",
    "                        standardize_cont = True):\n",
    "    \"\"\"\n",
    "    Create the incidents dataframe from the raw reports dataframe.\n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    reports_df: pandas.DataFrame\n",
    "        the raw reports dataframe\n",
    "    reports_identifier_col: str\n",
    "        the column name of the report identifier; if not specified, the index of the dataframe will be used\n",
    "    incident_identifier_col: str\n",
    "        the column name of the incident identifier, needs to be specified to identify unique incidents\n",
    "    observation_start_col: str, or list of str\n",
    "        the column name of the observation start time, needs to be specified to identify start time of observation interval, within a unique incident\n",
    "    observation_start_agg_method: str, or list of str\n",
    "        the aggregation method for the observation start time, available options are 'min', 'max', 'mean', 'median', 'first', 'last'\n",
    "        if not specified, 'min' will be used for all columns\n",
    "    observation_end_col: str, or list of str\n",
    "        the column name of the observation end time, needs to be specified to identify end time of observation interval, within a unique incident\n",
    "    observation_end_agg_method: str, or list of str\n",
    "        the aggregation method for the observation end time, available options are 'min', 'max', 'mean', 'median', 'first', 'last'\n",
    "        if not specified, 'min' will be used for all columns\n",
    "    max_duration: int\n",
    "        the maximum duration of the observation interval in days, default is 100 days\n",
    "    covariates_cont: str, or list of str\n",
    "        the column names of the continuous covariates included in the model\n",
    "    covariates_cont_agg_method: str, or list of str\n",
    "        the aggregation method for the continuous covariates, available options are 'min', 'max', 'mean', 'median', 'first', 'last'\n",
    "        if not specified, 'first' will be used for all columns\n",
    "    covariates_cat: str, or list of str\n",
    "        the column names of the categorical covariates included in the model\n",
    "    covariates_cat_agg_method: str, or list of str\n",
    "        the aggregation method for the categorical covariates, available options are 'first', 'last', 'mode'\n",
    "        if not specified, 'first' will be used for all columns\n",
    "    dropna: bool\n",
    "        whether to drop rows with missing values in the covariates columns, before aggregating the covariates\n",
    "    filter_short_duration: bool or float\n",
    "        whether to filter out incidents with duration shorter than 0.1 day, or the specified duration in days\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(reports_df, pd.DataFrame), \"reports_df must be a pandas.DataFrame\"\n",
    "    assert isinstance(reports_identifier_col, str) or reports_identifier_col is None, \"reports_identifier_col must be a string\"\n",
    "    assert isinstance(incident_identifier_col, str), \"incident_identifier_col must be a string\"\n",
    "    assert isinstance(observation_start_col, str) or isinstance(observation_start_col, list), \"observation_start_col must be a string or list\"\n",
    "    if observation_start_agg_method is None:\n",
    "        observation_start_agg_method = ['min'] * len(observation_start_col)\n",
    "    \n",
    "    assert isinstance(observation_end_col, str) or isinstance(observation_end_col, list), \"observation_end_col must be a string or list\"\n",
    "    if observation_end_agg_method is None:\n",
    "        observation_end_agg_method = ['min'] * len(observation_end_col)\n",
    "    \n",
    "    assert isinstance(max_duration, int), \"max_duration must be an integer\"\n",
    "    assert covariates_cat is not None or covariates_cont is not None, \"at least one covariate must be specified\"\n",
    "\n",
    "    if covariates_cont is not None:\n",
    "        assert isinstance(covariates_cont, str) or isinstance(covariates_cont, list), \"covariates_cont must be a string or list\"\n",
    "        if covariates_cont_agg_method is None:\n",
    "            covariates_cont_agg_method = ['first'] * len(covariates_cont)\n",
    "    \n",
    "    if covariates_cat is not None:\n",
    "        assert isinstance(covariates_cat, str) or isinstance(covariates_cat, list), \"covariates_cat must be a string or list\"\n",
    "        if covariates_cat_agg_method is None:\n",
    "            covariates_cat_agg_method = ['first'] * len(covariates_cat)\n",
    "    \n",
    "    assert isinstance(dropna, bool), \"dropna must be a boolean\"\n",
    "    assert isinstance(filter_short_duration, bool) or isinstance(filter_short_duration, int) or isinstance(filter_short_duration, float), \"filter_short_duration must be a boolean, integer, or float\"\n",
    "\n",
    "    assert standardize_cont <= dropna, \"only if dropna is True, standardize_cont can be True\"\n",
    "\n",
    "\n",
    "    columns = reports_df.columns\n",
    "    assert incident_identifier_col in columns, \"incident_identifier_col must be a column in reports_df\"\n",
    "    assert all([col in columns for col in observation_start_col]), \"observation_start_col must be a column in reports_df\"\n",
    "    assert all([col in columns for col in observation_end_col]), \"observation_end_col must be a column in reports_df\"\n",
    "\n",
    "    # if reports_identifier_col is not specified, use the index of the dataframe\n",
    "    if reports_identifier_col is None:\n",
    "        reports_df = reports_df.reset_index()\n",
    "        reports_identifier_col = 'index'\n",
    "\n",
    "    # calculate the observation start and end time for each incident\n",
    "    df = reports_df.copy()\n",
    "    grouped = calculate_observation_start_end_time(df, \n",
    "                                                   incident_identifier_col, \n",
    "                                                   observation_start_col,\n",
    "                                                   observation_start_agg_method,\n",
    "                                                   observation_end_col, \n",
    "                                                   observation_end_agg_method, \n",
    "                                                   max_duration)\n",
    "\n",
    "    df = df.merge(grouped, on=incident_identifier_col, how='left')\n",
    "\n",
    "    # evaluate if the report is within the observation interval\n",
    "    df['is_within_observation_interval'] = (df['SRCreatedDate'] > df['observation_start_time']) & (df['SRCreatedDate'] <= df['observation_end_time'])\n",
    "\n",
    "    # aggregate the incidents\n",
    "    dfmain = df.groupby(incident_identifier_col).agg({'is_within_observation_interval': 'sum',\n",
    "                                                   'observation_start_time': 'first',\n",
    "                                                   'observation_end_time': 'first'}).reset_index()\n",
    "    dfmain.rename(columns={'is_within_observation_interval': 'num_duplicates'}, inplace=True)\n",
    "    dfmain['num_duplicates'] = dfmain['num_duplicates'].astype(int)\n",
    "    dfmain['duration'] = (dfmain['observation_end_time'] - dfmain['observation_start_time']).dt.total_seconds() / (24 * 60 * 60)\n",
    "    if isinstance(filter_short_duration, bool):\n",
    "        if filter_short_duration is True:\n",
    "            dfmain = dfmain.query('duration > 0.1')\n",
    "    elif isinstance(filter_short_duration, (int, float)):\n",
    "        dfmain = dfmain.query('duration > @filter_short_duration')\n",
    "    dfmaincols_to_keep = [incident_identifier_col, 'num_duplicates', 'duration']\n",
    "    dfmain = dfmain[dfmaincols_to_keep]\n",
    "\n",
    "\n",
    "    # aggregate the continuous covariates \n",
    "    if covariates_cont is not None:\n",
    "        dfcov_cont = df.groupby(incident_identifier_col).agg(dict(zip(covariates_cont, covariates_cont_agg_method))).reset_index()\n",
    "        dfmain = dfmain.merge(dfcov_cont, on=incident_identifier_col, how='left')\n",
    "    if covariates_cat is not None:\n",
    "        dfcov_cat = df.groupby(incident_identifier_col).agg(dict(zip(covariates_cat, covariates_cat_agg_method))).reset_index()\n",
    "        dfmain = dfmain.merge(dfcov_cat, on=incident_identifier_col, how='left')\n",
    "    if dropna:\n",
    "        dfmain.dropna(inplace=True)\n",
    "        if standardize_cont:\n",
    "            dfmain[covariates_cont] = (dfmain[covariates_cont] - dfmain[covariates_cont].mean()) / dfmain[covariates_cont].std()\n",
    "    \n",
    "    return dfmain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_identifier_col = 'IncidentGlobalID'\n",
    "observation_start_col = ['SRCreatedDate']\n",
    "observation_start_agg_method = ['min']\n",
    "observation_end_col = ['InsCreatedDate', 'WOCreatedDate']\n",
    "observation_end_agg_method = ['min', 'min']\n",
    "covariate_cont = ['RiskRating']\n",
    "covariate_cat = ['SRCategory', 'BoroughCode']\n",
    "ddf = create_incidents_df(df,\n",
    "                            incident_identifier_col = incident_identifier_col, \n",
    "                            observation_start_col = observation_start_col,\n",
    "                            observation_start_agg_method = observation_start_agg_method,\n",
    "                            observation_end_col = observation_end_col, \n",
    "                            observation_end_agg_method = observation_end_agg_method,\n",
    "                            max_duration = 50,\n",
    "                            covariates_cont = covariate_cont,\n",
    "                            covariates_cat = covariate_cat,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_regression(incidents_df, \n",
    "                                covariate_cat, \n",
    "                                covariate_cont):\n",
    "    \"\"\"\n",
    "    Prepare the data for regression.\n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    incidents_df: pandas.DataFrame\n",
    "        the incidents dataframe, generated by create_incidents_df\n",
    "    covariate_cont: str, or list of str\n",
    "        the column names of the continuous covariates included in the model\n",
    "    covariate_cat: str, or list of str\n",
    "        the column names of the categorical covariates included in the model\n",
    "    \"\"\"\n",
    "    assert isinstance(incidents_df, pd.DataFrame), \"incidents_df must be a pandas.DataFrame\"\n",
    "    assert isinstance(covariate_cat, str) or isinstance(covariate_cat, list), \"covariate_cat must be a string or list\"\n",
    "    assert isinstance(covariate_cont, str) or isinstance(covariate_cont, list), \"covariate_cont must be a string or list\"\n",
    "    assert covariate_cat is not None or covariate_cont is not None, \"at least one covariate must be specified\"\n",
    "    assert all([col in incidents_df.columns for col in covariate_cat]), \"covariate_cat must be a column in incidents_df\"\n",
    "    assert all([col in incidents_df.columns for col in covariate_cont]), \"covariate_cont must be a column in incidents_df\"\n",
    "\n",
    "    # prepare the formula for regression\n",
    "    formula = 'num_duplicates ~ 1 + '\n",
    "    if covariate_cont is not None:\n",
    "        if isinstance(covariate_cont, str):\n",
    "            formula += covariate_cont\n",
    "        else:\n",
    "            formula += ' + '.join(covariate_cont)\n",
    "    if covariate_cat is not None:\n",
    "        if isinstance(covariate_cat, str):\n",
    "            formula += ' + C(' + covariate_cat + ')'\n",
    "        else:\n",
    "            formula += ' + ' + ' + '.join(['C(' + col + ')' for col in covariate_cat])\n",
    "    \n",
    "    # prepare the data for regression\n",
    "    y, X = dmatrices(formula, incidents_df, return_type='dataframe')\n",
    "    duration = incidents_df['duration']\n",
    "    \n",
    "    return y, X, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(y, X, duration, model_type = 'standard'):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: pandas.DataFrame\n",
    "        the response variable\n",
    "    X: pandas.DataFrame\n",
    "        the covariates\n",
    "    duration: pandas.Series\n",
    "        the duration of the incidents\n",
    "    model_type: str\n",
    "        the type of the model, available options are 'standard' and 'zeroinflated'\n",
    "    \"\"\"\n",
    "    assert isinstance(y, pd.DataFrame), \"y must be a pandas.Series\"\n",
    "    assert isinstance(X, pd.DataFrame), \"X must be a pandas.DataFrame\"\n",
    "    assert isinstance(duration, pd.Series), \"duration must be a pandas.Series\"\n",
    "\n",
    "    # fit the model\n",
    "    if model_type == 'standard':\n",
    "        res = sm.GLM(y, X, exposure = duration, family = sm.families.Poisson()).fit(maxiter = 1000, method = 'bfgs')\n",
    "    elif model_type == 'zeroinflated':\n",
    "        # increase iterations to avoid convergence warning\n",
    "        res = sm.ZeroInflatedPoisson(y, X, exog_infl = None, exposure = duration, \n",
    "                                                          ).fit(maxiter = 1000, method = 'bfgs')\n",
    "    print(res.summary())\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X, duration = prepare_data_for_regression(ddf, covariate_cat, covariate_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534596\n",
      "         Iterations: 138\n",
      "         Function evaluations: 139\n",
      "         Gradient evaluations: 139\n",
      "                     ZeroInflatedPoisson Regression Results                    \n",
      "===============================================================================\n",
      "Dep. Variable:          num_duplicates   No. Observations:                 6660\n",
      "Model:             ZeroInflatedPoisson   Df Residuals:                     6646\n",
      "Method:                            MLE   Df Model:                           13\n",
      "Date:                 Wed, 04 Oct 2023   Pseudo R-squ.:                 0.08466\n",
      "Time:                         17:57:01   Log-Likelihood:                -3560.4\n",
      "converged:                        True   LL-Null:                       -3889.7\n",
      "Covariance Type:             nonrobust   LLR p-value:                2.376e-132\n",
      "========================================================================================================\n",
      "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "inflate_const                            0.9840      0.047     20.981      0.000       0.892       1.076\n",
      "Intercept                               -2.1944      0.145    -15.157      0.000      -2.478      -1.911\n",
      "C(SRCategory)[T.Illegal Tree Damage]    -1.2568      0.143     -8.792      0.000      -1.537      -0.977\n",
      "C(SRCategory)[T.Plant Tree]              0.2949      0.735      0.401      0.688      -1.146       1.736\n",
      "C(SRCategory)[T.Prune]                  -1.6744      0.131    -12.808      0.000      -1.931      -1.418\n",
      "C(SRCategory)[T.Remove Debris]          -0.9133      0.251     -3.636      0.000      -1.406      -0.421\n",
      "C(SRCategory)[T.Remove Stump]            0.8977      1.349      0.665      0.506      -1.747       3.542\n",
      "C(SRCategory)[T.Remove Tree]            -1.5975      0.107    -14.960      0.000      -1.807      -1.388\n",
      "C(SRCategory)[T.Rescue/Preservation]    -2.2878      0.667     -3.428      0.001      -3.596      -0.980\n",
      "C(SRCategory)[T.Root/Sewer/Sidewalk]    -3.1532      0.316     -9.983      0.000      -3.772      -2.534\n",
      "C(BoroughCode)[T.Brooklyn]               0.7337      0.152      4.828      0.000       0.436       1.031\n",
      "C(BoroughCode)[T.Manhattan]              0.7103      0.181      3.920      0.000       0.355       1.065\n",
      "C(BoroughCode)[T.Queens]                 0.5992      0.156      3.842      0.000       0.294       0.905\n",
      "C(BoroughCode)[T.Staten Island]          0.5825      0.177      3.289      0.001       0.235       0.930\n",
      "RiskRating                               0.2985      0.043      6.981      0.000       0.215       0.382\n",
      "========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "res = train_model(y, X, duration, model_type='zeroinflated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_reporting_delay(res, X):\n",
    "    \"\"\"\n",
    "    Generate the predicted reporting delay.\n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    res: the fitted model\n",
    "    X: pandas.DataFrame\n",
    "        the covariates\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate the predicted reporting delay\n",
    "    predicted_reporting_rate = res.predict(X)\n",
    "    predicted_reporting_delay = 1 / predicted_reporting_rate\n",
    "\n",
    "    return predicted_reporting_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_delays_to_incidents_df(incidents_df, delays):\n",
    "    \"\"\"\n",
    "    Append the predicted reporting delay to the incidents dataframe.\n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    incidents_df: pandas.DataFrame\n",
    "        the incidents dataframe, generated by create_incidents_df\n",
    "    delays: the predicted reporting delay\n",
    "    \"\"\"\n",
    "    assert isinstance(incidents_df, pd.DataFrame), \"incidents_df must be a pandas.DataFrame\"\n",
    "    assert len(delays) == len(incidents_df), \"the length of delays must be the same as the length of incidents_df\"\n",
    "\n",
    "    incidents_df['predicted_reporting_delay'] = delays\n",
    "\n",
    "    return incidents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = append_delays_to_incidents_df(ddf, generate_predicted_reporting_delay(res, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentGlobalID</th>\n",
       "      <th>num_duplicates</th>\n",
       "      <th>duration</th>\n",
       "      <th>RiskRating</th>\n",
       "      <th>SRCategory</th>\n",
       "      <th>BoroughCode</th>\n",
       "      <th>predicted_reporting_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00019105-8135-4AC1-A4B7-003C7793EB03</td>\n",
       "      <td>0</td>\n",
       "      <td>4.971748</td>\n",
       "      <td>0.100711</td>\n",
       "      <td>Remove Tree</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>158.129115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003AE41-2F12-4AB3-9452-5C9AA6BA1F37</td>\n",
       "      <td>0</td>\n",
       "      <td>3.918750</td>\n",
       "      <td>0.100711</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>Queens</td>\n",
       "      <td>17.579962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000659A4-B47D-4C43-8C44-D5C86D149F6E</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767164</td>\n",
       "      <td>-0.465790</td>\n",
       "      <td>Remove Tree</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>92.039213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007E6E1-65AF-4CC5-88EA-F814B84EE3A4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128056</td>\n",
       "      <td>0.100711</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>Queens</td>\n",
       "      <td>17.579962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008BE00-79E8-4DF7-8636-D1409B011957</td>\n",
       "      <td>0</td>\n",
       "      <td>0.554387</td>\n",
       "      <td>-1.032290</td>\n",
       "      <td>Remove Tree</td>\n",
       "      <td>Queens</td>\n",
       "      <td>121.801094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8567</th>\n",
       "      <td>FFCB1218-3908-4777-99B7-B91A4821751C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673461</td>\n",
       "      <td>1.233713</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>10.958604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>FFCD3B76-0715-4F72-B851-4D5C8E0B7334</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009942</td>\n",
       "      <td>1.233713</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>Queens</td>\n",
       "      <td>12.535821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8569</th>\n",
       "      <td>FFCE86B9-41E8-4E49-BD3A-5D10B0DB8E0A</td>\n",
       "      <td>0</td>\n",
       "      <td>1.995451</td>\n",
       "      <td>0.100711</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>15.368107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>FFEADCE8-E56D-44F0-8000-92894C4330EB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>1.233713</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>Queens</td>\n",
       "      <td>12.535821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>FFF78875-31D8-4E81-85CC-D2A3BE1DF16A</td>\n",
       "      <td>0</td>\n",
       "      <td>2.841470</td>\n",
       "      <td>0.667212</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>27.027828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6660 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          IncidentGlobalID  num_duplicates  duration  \\\n",
       "0     00019105-8135-4AC1-A4B7-003C7793EB03               0  4.971748   \n",
       "1     0003AE41-2F12-4AB3-9452-5C9AA6BA1F37               0  3.918750   \n",
       "2     000659A4-B47D-4C43-8C44-D5C86D149F6E               0  0.767164   \n",
       "3     0007E6E1-65AF-4CC5-88EA-F814B84EE3A4               0  0.128056   \n",
       "4     0008BE00-79E8-4DF7-8636-D1409B011957               0  0.554387   \n",
       "...                                    ...             ...       ...   \n",
       "8567  FFCB1218-3908-4777-99B7-B91A4821751C               0  0.673461   \n",
       "8568  FFCD3B76-0715-4F72-B851-4D5C8E0B7334               0  1.009942   \n",
       "8569  FFCE86B9-41E8-4E49-BD3A-5D10B0DB8E0A               0  1.995451   \n",
       "8572  FFEADCE8-E56D-44F0-8000-92894C4330EB               0  0.963889   \n",
       "8573  FFF78875-31D8-4E81-85CC-D2A3BE1DF16A               0  2.841470   \n",
       "\n",
       "      RiskRating   SRCategory BoroughCode  predicted_reporting_delay  \n",
       "0       0.100711  Remove Tree       Bronx                 158.129115  \n",
       "1       0.100711       Hazard      Queens                  17.579962  \n",
       "2      -0.465790  Remove Tree   Manhattan                  92.039213  \n",
       "3       0.100711       Hazard      Queens                  17.579962  \n",
       "4      -1.032290  Remove Tree      Queens                 121.801094  \n",
       "...          ...          ...         ...                        ...  \n",
       "8567    1.233713       Hazard    Brooklyn                  10.958604  \n",
       "8568    1.233713       Hazard      Queens                  12.535821  \n",
       "8569    0.100711       Hazard    Brooklyn                  15.368107  \n",
       "8572    1.233713       Hazard      Queens                  12.535821  \n",
       "8573    0.667212       Hazard       Bronx                  27.027828  \n",
       "\n",
       "[6660 rows x 7 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "underreporting_estimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
